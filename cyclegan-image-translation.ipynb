{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1567181,"sourceType":"datasetVersion","datasetId":925857}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:35:38.308939Z","iopub.execute_input":"2025-02-22T09:35:38.309370Z","iopub.status.idle":"2025-02-22T09:35:40.854274Z","shell.execute_reply.started":"2025-02-22T09:35:38.309337Z","shell.execute_reply":"2025-02-22T09:35:40.853617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:35:40.855344Z","iopub.execute_input":"2025-02-22T09:35:40.855726Z","iopub.status.idle":"2025-02-22T09:35:40.875595Z","shell.execute_reply.started":"2025-02-22T09:35:40.855692Z","shell.execute_reply":"2025-02-22T09:35:40.874775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"class CycleGANDataset(Dataset):\n    def __init__(self, root, transform=None):\n        self.transform = transform\n\n        # Path to domain A (e.g., Summer) and domain B (e.g., Winter)\n        self.dir_A = os.path.join(root, 'trainA')\n        self.dir_B = os.path.join(root, 'trainB')\n\n        self.files_A = sorted(os.listdir(self.dir_A))\n        self.files_B = sorted(os.listdir(self.dir_B))\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))\n\n    def __getitem__(self, index):\n        img_A_path = os.path.join(self.dir_A, self.files_A[index % len(self.files_A)])\n        img_B_path = os.path.join(self.dir_B, self.files_B[index % len(self.files_B)])\n\n        img_A = Image.open(img_A_path).convert('RGB')\n        img_B = Image.open(img_B_path).convert('RGB')\n\n        if self.transform:\n            img_A = self.transform(img_A)\n            img_B = self.transform(img_B)\n\n        return {'A': img_A, 'B': img_B}\n\n# Define image transformations (resize, normalization, etc.)\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Load Dataset\ndataset = CycleGANDataset(root='/kaggle/input/summer2winter-yosemite', transform=transform)\ndataloader = DataLoader(dataset, batch_size =4, shuffle=True)\n\n# Example check\nsample = next(iter(dataloader))\nprint(sample['A'].shape, sample['B'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:35:40.877649Z","iopub.execute_input":"2025-02-22T09:35:40.877963Z","iopub.status.idle":"2025-02-22T09:35:41.149172Z","shell.execute_reply.started":"2025-02-22T09:35:40.877933Z","shell.execute_reply":"2025-02-22T09:35:41.148029Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"class ResnetBlock(nn.Module):\n    def __init__(self, dim):\n        super(ResnetBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(dim, dim, kernel_size=3, padding=1, bias=False),\n            nn.InstanceNorm2d(dim),\n            nn.ReLU(True),\n            nn.Conv2d(dim, dim, kernel_size=3, padding=1, bias=False),\n            nn.InstanceNorm2d(dim),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass GeneratorResNet(nn.Module):\n    def __init__(self, input_channels=3, output_channels=3, n_residual_blocks=9):\n        super(GeneratorResNet, self).__init__()\n        model = [\n            nn.Conv2d(input_channels, 64, kernel_size=7, padding=3, bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(True)\n        ]\n\n        # Downsampling\n        model += [\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(True)\n        ]\n\n        # Residual blocks\n        for _ in range(n_residual_blocks):\n            model += [ResnetBlock(256)]\n\n        # Upsampling\n        model += [\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(True)\n        ]\n\n        model += [nn.Conv2d(64, output_channels, kernel_size=7, padding=3), nn.Tanh()]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass Discriminator(nn.Module):\n    def __init__(self, input_channels=3):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n# Example usage\ngenerator = GeneratorResNet()\ndiscriminator = Discriminator()\n\nprint(generator)\nprint(discriminator)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:35:41.150340Z","iopub.execute_input":"2025-02-22T09:35:41.150642Z","iopub.status.idle":"2025-02-22T09:35:41.258393Z","shell.execute_reply.started":"2025-02-22T09:35:41.150621Z","shell.execute_reply":"2025-02-22T09:35:41.257503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function to Display Images","metadata":{}},{"cell_type":"code","source":"def denormalize(img_tensor):\n    \"\"\"Convert a normalized tensor image to a displayable format.\"\"\"\n    img = img_tensor.cpu().detach().numpy()\n    img = (img * 0.5) + 0.5  # Denormalize from [-1, 1] to [0, 1]\n    img = np.transpose(img, (1, 2, 0))  # C, H, W -> H, W, C\n    return img\n\ndef show_training_images(real_A, fake_B, real_B, fake_A):\n    plt.figure(figsize=(8, 8))\n\n    plt.subplot(2, 2, 1)\n    plt.imshow(denormalize(real_A))\n    plt.title(\"Real A (e.g., Summer)\")\n    plt.axis(\"off\")\n\n    plt.subplot(2, 2, 2)\n    plt.imshow(denormalize(fake_B))\n    plt.title(\"Fake B (e.g., Winter)\")\n    plt.axis(\"off\")\n\n    plt.subplot(2, 2, 3)\n    plt.imshow(denormalize(real_B))\n    plt.title(\"Real B (e.g., Winter)\")\n    plt.axis(\"off\")\n\n    plt.subplot(2, 2, 4)\n    plt.imshow(denormalize(fake_A))\n    plt.title(\"Fake A (e.g., Summer)\")\n    plt.axis(\"off\")\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:35:41.259172Z","iopub.execute_input":"2025-02-22T09:35:41.259404Z","iopub.status.idle":"2025-02-22T09:35:41.265350Z","shell.execute_reply.started":"2025-02-22T09:35:41.259384Z","shell.execute_reply":"2025-02-22T09:35:41.264510Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"generator_A2B = GeneratorResNet().to(device)\ngenerator_B2A = GeneratorResNet().to(device)\ndiscriminator_A = Discriminator().to(device)\ndiscriminator_B = Discriminator().to(device)\n\n# Loss functions\ncriterion_GAN = nn.MSELoss()\ncriterion_cycle = nn.L1Loss()\n\n# Optimizers with adjusted learning rates\noptimizer_G = optim.Adam(list(generator_A2B.parameters()) + list(generator_B2A.parameters()), lr=0.0001, betas=(0.5, 0.999))\noptimizer_D_A = optim.Adam(discriminator_A.parameters(), lr=0.00005, betas=(0.5, 0.999))\noptimizer_D_B = optim.Adam(discriminator_B.parameters(), lr=0.00005, betas=(0.5, 0.999))\n\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    for i, batch in progress_bar :\n        # Get one image from the batch\n        real_A = batch['A'][0].unsqueeze(0).to(device)  # Add batch dimension\n        real_B = batch['B'][0].unsqueeze(0).to(device)  # Add batch dimension\n\n        # Generate fake images\n        fake_B = generator_A2B(real_A)\n        fake_A = generator_B2A(real_B)\n\n        # Reconstruct images (cycle consistency)\n        rec_A = generator_B2A(fake_B)\n        rec_B = generator_A2B(fake_A)\n\n        # Losses for the Generators\n        loss_GAN_A2B = criterion_GAN(discriminator_B(fake_B), torch.ones_like(discriminator_B(fake_B)))\n        loss_GAN_B2A = criterion_GAN(discriminator_A(fake_A), torch.ones_like(discriminator_A(fake_A)))\n\n        loss_cycle_A = criterion_cycle(rec_A, real_A)\n        loss_cycle_B = criterion_cycle(rec_B, real_B)\n\n        # Total Generator Loss\n        loss_G = loss_GAN_A2B + loss_GAN_B2A + 10.0 * (loss_cycle_A + loss_cycle_B)\n\n        # Update Generators\n        optimizer_G.zero_grad()\n        loss_G.backward()\n        optimizer_G.step()\n\n        # Discriminator Losses\n        # Discriminator A (real vs fake)\n        loss_D_A = criterion_GAN(discriminator_A(real_A), torch.ones_like(discriminator_A(real_A))) + \\\n                   criterion_GAN(discriminator_A(fake_A.detach()), torch.zeros_like(discriminator_A(fake_A)))\n        optimizer_D_A.zero_grad()\n        loss_D_A.backward()\n        optimizer_D_A.step()\n\n        # Discriminator B (real vs fake)\n        loss_D_B = criterion_GAN(discriminator_B(real_B), torch.ones_like(discriminator_B(real_B))) + \\\n                   criterion_GAN(discriminator_B(fake_B.detach()), torch.zeros_like(discriminator_B(fake_B)))\n        optimizer_D_B.zero_grad()\n        loss_D_B.backward()\n        optimizer_D_B.step()\n\n        if i % 200 == 0:\n            # Visualize the results\n            show_training_images(real_A[0], fake_B[0], real_B[0], fake_A[0])\n\n    print(f\"Epoch [{epoch}/{num_epochs}], Batch [{i}], Loss G: {loss_G.item()}, Loss D_A: {loss_D_A.item()}, Loss D_B: {loss_D_B.item()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T09:36:39.380132Z","iopub.execute_input":"2025-02-22T09:36:39.380517Z","iopub.status.idle":"2025-02-22T09:36:53.173289Z","shell.execute_reply.started":"2025-02-22T09:36:39.380486Z","shell.execute_reply":"2025-02-22T09:36:53.172223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Saving Models","metadata":{}},{"cell_type":"code","source":"torch.save(generator_A2B.state_dict(), 'generator_A2B.pth')\ntorch.save(generator_B2A.state_dict(), 'generator_B2A.pth')\ntorch.save(discriminator_A.state_dict(), 'discriminator_A.pth')\ntorch.save(discriminator_B.state_dict(), 'discriminator_B.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}